# ============================
# LABORATORIO 1 - MINERÍA DE TEXTO
# Proyecto Gutenberg
# Autor: Alejandro De Mendoza
# Fecha: Febrero 2026
# ============================
# ============================
# 1. CARGAR LIBRERÍAS
# ============================
library(gutenbergr)
library(tidytext)
library(dplyr)
library(tidyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(tm)
# ============================
# 2. DESCARGAR LIBROS
# ============================
book1 <- gutenberg_download(345)  # Dracula
book2 <- gutenberg_download(84)   # Frankenstein
book3 <- gutenberg_download(35)   # Time Machine
book4 <- gutenberg_download(36)   # War of the Worlds
# ============================
# 3. ASIGNAR NOMBRES
# ============================
book1$book <- "Dracula"
book2$book <- "Frankenstein"
book3$book <- "Time Machine"
book4$book <- "War of the Worlds"
# ============================
# 4. UNIR CORPUS
# ============================
corpus <- bind_rows(book1, book2, book3, book4)
cat("Corpus creado con", nrow(corpus), "líneas de texto\n")
# ============================
# 5. TOKENIZAR
# ============================
words <- corpus %>%
unnest_tokens(word, text)
cat("Total de palabras tokenizadas:", nrow(words), "\n")
# ============================
# 6. ELIMINAR STOPWORDS
# ============================
data("stop_words")
words_clean <- words %>%
anti_join(stop_words)
cat("Palabras después de eliminar stopwords:", nrow(words_clean), "\n")
# ============================
# 7. TOP 15 PALABRAS FRECUENTES
# ============================
top_words <- words_clean %>%
count(book, word, sort = TRUE) %>%
group_by(book) %>%
slice_max(n, n = 15)
print(top_words)
# ============================
# 8. GRÁFICO DE FRECUENCIAS
# ============================
top_words %>%
ggplot(aes(x = reorder(word, n), y = n, fill = book)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~book, scales = "free") +
labs(
title = "Top 15 palabras más frecuentes por libro",
x = "Palabra",
y = "Frecuencia"
) +
theme_minimal()
# ============================
# 9. NUBES DE PALABRAS
# ============================
cat("\n=== GENERANDO NUBES DE PALABRAS ===\n")
# Opción A: 4 nubes en una sola ventana (2x2)
par(mfrow = c(2, 2), mar = c(1, 1, 3, 1))
libros <- c("Dracula", "Frankenstein", "Time Machine", "War of the Worlds")
colores <- list(
brewer.pal(8, "Set1"),
brewer.pal(8, "Set2"),
brewer.pal(8, "Paired"),
brewer.pal(8, "Dark2")
)
for(i in 1:length(libros)) {
palabras_libro <- words_clean %>%
filter(book == libros[i]) %>%
count(word, sort = TRUE)
wordcloud(
words = palabras_libro$word,
freq = palabras_libro$n,
max.words = 100,
min.freq = 5,
random.order = FALSE,
colors = colores[[i]],
scale = c(3, 0.5)
)
title(main = libros[i], cex.main = 1.5, font.main = 2)
}
par(mfrow = c(1, 1))  # Restaurar configuración
cat("Nubes de palabras generadas exitosamente\n")
# Opción B: Nubes individuales (descomenta si quieres verlas grandes)
# for(libro in libros) {
#   palabras_libro <- words_clean %>%
#     filter(book == libro) %>%
#     count(word, sort = TRUE)
#
#   wordcloud(
#     words = palabras_libro$word,
#     freq = palabras_libro$n,
#     max.words = 150,
#     min.freq = 5,
#     random.order = FALSE,
#     colors = brewer.pal(8, "Dark2"),
#     scale = c(4, 0.5)
#   )
#
#   title(main = paste("Nube de Palabras -", libro),
#         cex.main = 2, font.main = 2)
#
#   readline(prompt = "Presiona Enter para la siguiente nube...")
# }
# ============================
# 10. CÁLCULO TF-IDF
# ============================
cat("\n=== CALCULANDO TF-IDF ===\n")
tf_idf <- words_clean %>%
count(book, word, sort = TRUE) %>%
bind_tf_idf(word, book, n) %>%
arrange(desc(tf_idf))
head(tf_idf, 10)
# ============================
# 11. TOP 15 TÉRMINOS CARACTERÍSTICOS
# ============================
top_tf_idf <- tf_idf %>%
group_by(book) %>%
slice_max(tf_idf, n = 15)
print(top_tf_idf)
# ============================
# 12. GRÁFICO TF-IDF
# ============================
top_tf_idf %>%
ggplot(aes(x = reorder(word, tf_idf), y = tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~book, scales = "free") +
labs(
title = "Top 15 términos más característicos (TF-IDF)",
x = "Palabra",
y = "TF-IDF"
) +
theme_minimal()
# ============================
# 13. CREAR BIGRAMAS
# ============================
cat("\n=== GENERANDO BIGRAMAS ===\n")
bigrams <- corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# Separar en palabra1 y palabra2
bigrams_separated <- bigrams %>%
separate(bigram, into = c("word1", "word2"), sep = " ")
# Eliminar stopwords
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word)
cat("Bigramas creados:", nrow(bigrams_filtered), "\n")
# ============================
# 14. ASOCIACIONES - HELSING
# ============================
cat("\n=== ASOCIACIONES CON 'HELSING' ===\n")
helsing_assoc <- bigrams_filtered %>%
filter(word1 == "helsing" | word2 == "helsing") %>%
count(word1, word2, sort = TRUE)
print(head(helsing_assoc, 10))
# ============================
# 15. ASOCIACIONES - MARTIANS
# ============================
cat("\n=== ASOCIACIONES CON 'MARTIANS' ===\n")
martians_assoc <- bigrams_filtered %>%
filter(word1 == "martians" | word2 == "martians") %>%
count(word1, word2, sort = TRUE)
print(head(martians_assoc, 10))
# ============================
# FIN DEL LABORATORIO
# ============================
cat("\n✓ LABORATORIO COMPLETADO EXITOSAMENTE\n")
cat("Todos los análisis han sido generados\n")
source("~/Estudio/Carrera Ingeniería Informatica/Sexto semestre/Procesadores de Leguajes/Laboratorio No. 1/Laboratorio_TextMining/laboratorio1.R", echo = TRUE)
